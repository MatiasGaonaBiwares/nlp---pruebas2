{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9fbd25-cd7a-4918-81ab-89c03751d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso empieza con:\n",
    "#     Limpieza de frases/palabras que no son relevantes en PQRS\n",
    "#     20 frases mas comunes para 1,2,3 y 4 palabras (total de 80)\n",
    "#     Luego, si:\n",
    "#         Esas frases estan compuestas por palabras que contenian a algo eliminado, se elimina (queda un espacio y no se contempla)\n",
    "#         Esas frases estan siendo repetidas en otras (ejemplo: Mas rapido, mas rapido contestaron. Nos quedamos con la mas larga, \"mas rapido contestaron\")\n",
    "#         De esas 80 quedan unas 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f4498c-a511-4449-b5b5-5ecc8a59e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e529fc39078c>:11: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter    \n",
    "from nltk.probability import FreqDist\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bef95ad5-c65d-4937-9efc-ffe08bec2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = (pd.read_excel('Encuestas_TemasyFrases_stop_words_sin_tilde1.xlsx')) \n",
    "stop_words=list(stop_words['stopwords'])\n",
    "\n",
    "eliminar_frases=['usuario se comunica','usuaria se comunica','confronta exitosa','usuario solicita información',\n",
    " 'usuaria solicita información','se informa que','se le indica correo','se realiza','se solicita','se genera certificación de pagos',\n",
    " 'se envía la solicitud al correo','por parte del usuariose envía','se genera certificación de pagos','del proyecto','se informa',\n",
    " 'se brinda','usuaria','solicita información','se informa que','usuario solicita','usuaria solicita','retroalimentacion','se toma solicitud',\n",
    " 'solicita','usuaria se comunica para manifestar inconformidad','usuario se comunica','se indica','se informa','cédula','celular','solicitud',\n",
    " 'cajero:','punto:','correo:','errada:','correc:','radicado:','nombre:','cc:','correo:','telefono:','direccion:','radicado:','os:',\n",
    " 'ps','usuario solicita','pago realizado','buenas tardes','datos personales','respuesta al correo electronico','correo electronico se indica','usuaria solicita',\n",
    " 'adjunta pantallazo','al correo sac','se lee articulo','se adjunta','pantallazo de correo','confronta no exitoso','usuario autoriza','buenas tardes',\n",
    " 'cordial saludo','correo electronico','dias habiles','buenos dias','respuesta al correo','autoriza respuesta','el dia de hoy','tiempo de gestion de','quedo atenta','muchas gracias','articulo de la ley','autoriza tiempo',\n",
    " 'ley','buen dia','pronta respuesta','cedula','numero de referencia','hasta la fecha','el nombre del titular']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f1d0454-e863-47a6-abea-8c50765fd88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo\n",
    "Encuestas = pd.read_excel('Encuestas_FrasesyTemas_muestra_textolibre.xlsx')\n",
    "# Encuestas.reset_index(inplace=True)\n",
    "Encuestas.rename(columns={'index':'index_inicial'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2deeae06-ef09-4f37-bc36-6217b3c078a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encuestas.rename(columns={'comentario':'Descripción'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4b718a-e589-42b5-8a31-8f721e8d6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encuestas['Descripción']=Encuestas['Descripción'].astype(str)\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: x.lower())\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub('se\\s[a-z]{1,10}','',str(x)))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub('á','a',str(x)))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub('é','e',str(x)))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub('í','i',str(x)))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub('ó','o',str(x)))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub('ú','u',str(x)))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub(r\"\"\"[\\n\\t]\"\"\",\" \",x))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub(\"\"\"[-*\\_¡!@#$:).;–,¿?&'_>/]{1,4}\"\"\",\"\",x))\n",
    "Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub(r\"\"\"[0-9]\"\"\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1861b38-d9c0-48a4-b207-f0584beeac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in eliminar_frases:\n",
    "    Encuestas['Descripción']=Encuestas['Descripción'].apply(lambda x: re.sub(f,'',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91452be5-54b9-421e-8f19-99fbbc19e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_token=re.sub(\"\"\"[,']\"\"\",'',str(list(Encuestas['Descripción'])))\n",
    "tokenized_word=word_tokenize(pa_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93935f1b-69cf-4357-82b6-e876ea2e174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(tokenized_word_0)):\n",
    "#     if tokenized_word_0[i]!=tokenized_word[i]:\n",
    "#         print(tokenized_word_0[i]+' '+tokenized_word[i])       \n",
    "# # efecto, siweb,sieweb,pqrs .. identificar las entidades con anterioridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e88450-15cc-42b6-81c5-e7c3b6bd00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qty_most_common=30\n",
    "def gen_frases(qty_words_ngram,max_stopwords,df):\n",
    "    global Top_words\n",
    "    global qty_most_common\n",
    "    Top_words=[]\n",
    "    Encuestas2=pd.DataFrame()\n",
    "    ongrams=ngrams(tokenized_word,qty_words_ngram)\n",
    "    ongrams=list(zip(ongrams))\n",
    "    ongrams=pd.DataFrame(ongrams)\n",
    "    ongrams['r']=0\n",
    "    for i in range(0,qty_words_ngram):\n",
    "        ongrams['val'+str(i)]=ongrams[0].apply(lambda x: x[i])\n",
    "        ongrams['w'+str(i)]=0\n",
    "        index_on_val=ongrams[ongrams['val'+str(i)].isin(stop_words)].index\n",
    "        ongrams.loc[index_on_val,'w'+str(i)]=1\n",
    "        ongrams['r']=ongrams['r']+ongrams['w'+str(i)]\n",
    "\n",
    "    ongrams=ongrams[(ongrams['r']<=max_stopwords)&(ongrams['w'+str(qty_words_ngram-1)]==0)] #La ultima condicion es para que no termine con un stopword\n",
    "    ongrams_=[]\n",
    "    ongrams.reset_index(inplace=True)\n",
    "\n",
    "    for i in range(len(ongrams[0])):\n",
    "        ongrams_.append(re.sub(\"\"\"[¡!@)#($:.;,¿?&'_]\"\"\",\"\",str(ongrams[0][i]))) #Agregar nan\n",
    "\n",
    "    \n",
    "    fdist = FreqDist((ongrams_))\n",
    "    \n",
    "    df['frases']=''\n",
    "    for i in range(0,qty_most_common):\n",
    "        index_frases=df[(df['Descripción'].str.contains(str(fdist.most_common(qty_most_common)[i][0])))&(df['frases']=='')].index\n",
    "        index_frases_duplicadas=df[(df['Descripción'].str.contains(str(fdist.most_common(qty_most_common)[i][0])))&(df['frases']!='')].index\n",
    "#Si, veo que esta en el top, pero que no está en las frases df['Descripción'], es porque son 2 palabras que entre medio tenian una frase que \n",
    "# se eliminó y queda un espacio grande entre medio que te lo considera dentro del top, pero cuando lo busca no lo encuentra,\n",
    "# porque no existe tal cual, sino con un espacio de por medio y una frase sin sentido.\n",
    "        df.loc[index_frases,'frases']=fdist.most_common(qty_most_common)[i][0]\n",
    "        Top_words.append(fdist.most_common(qty_most_common)[i][0])\n",
    "        aux2=df.loc[index_frases_duplicadas,:]\n",
    "        aux2.loc[:,'frases']=fdist.most_common(qty_most_common)[i][0]\n",
    "        Encuestas2=pd.concat([aux2,Encuestas2])\n",
    "#     Encuestas2.drop(columns=['level_0'])\n",
    "    Encuestas2.reset_index(inplace=True)\n",
    "#     Encuestas2.drop(columns=['level_0'])\n",
    "    df=pd.concat([df,Encuestas2])\n",
    "    Encuestas_con_frases=df[df['frases']!='']\n",
    "#     df['frases']=df['frases'].apply(lambda x: x.upper())\n",
    "#     Top_words=fdist.most_common(qty_most_common)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d14f530-8471-4f8b-be43-d771f8836cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_frases2=gen_frases(2,0,Encuestas) \n",
    "R_frases2=R_frases2[R_frases2['frases']!='']\n",
    "top_2_palabras=pd.DataFrame(Top_words)\n",
    "\n",
    "R_frases3=gen_frases(3,1,Encuestas) \n",
    "R_frases3=R_frases3[R_frases3['frases']!='']\n",
    "top_3_palabras=pd.DataFrame(Top_words)\n",
    "\n",
    "R_frases4=gen_frases(4,2,Encuestas) \n",
    "R_frases4=R_frases4[R_frases4['frases']!='']\n",
    "top_4_palabras=pd.DataFrame(Top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "956e871b-3fc4-4310-bd57-c6dc2f7f0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encuestas3=pd.concat([Encuestas,R_frases2])\n",
    "Encuestas3=pd.concat([Encuestas3,R_frases3])\n",
    "Encuestas3=pd.concat([Encuestas3,R_frases4])\n",
    "Encuestas3.sort_values(by='index',inplace=True)\n",
    "# Encuestas3.drop(columns=['level_0','index'],inplace=True)\n",
    "Encuestas3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a76e364-cfca-4624-83e4-fe1cde72f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESO PARA LIMIPAR FRASES SEMEJANTES DENTRO DE 4 PALABRAS. Repetir este proceso para 3 y 2 palabras\n",
    "\n",
    "eliminar=[]\n",
    "index_eliminar_2=[]\n",
    "index_eliminar_3=[]\n",
    "index_eliminar_4=[]\n",
    "top_2_palabras_n=top_2_palabras\n",
    "top_4_palabras_n=top_4_palabras\n",
    "top_3_palabras_n=top_3_palabras\n",
    "\n",
    "for j in range(0,qty_most_common): \n",
    "    \n",
    "    #Pensado para 20 palabras mas comunes de 4 palabras. Compara contra las de 4 y las de 3\n",
    "    qs=re.findall('[\\w]{1,15}',top_4_palabras_n[0][j])\n",
    "    # 4 palabras solo va a ir contra 3\n",
    "    for i in range(0,len(qs)):\n",
    "        for p1 in range(0,qty_most_common):\n",
    "            try: #Mira si hay 3 palabras segúidas repetidas dentro de los 4grams, si es asi lo elimina\n",
    "                if(((qs[i]+' '+qs[i+1]+' '+qs[i+2]) in top_4_palabras_n[0][p1])&(p1!=j)):\n",
    "                    eliminar.append(top_4_palabras_n[0][p1])\n",
    "                    top_4_palabras_n[0][p1]='-4'\n",
    "                    index_eliminar_4.append(p1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            try: #Mira si hay 2 palabras segúidas repetidas dentro de los 3grams, si es asi lo elimina\n",
    "                if((qs[i]+' '+qs[i+1]) in top_3_palabras_n[0][p1]):\n",
    "                    eliminar.append(top_3_palabras_n[0][p1])\n",
    "                    index_eliminar_3.append(p1)\n",
    "                    top_3_palabras_n[0][p1]='-4'\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try: #Mira si hay 2 palabras segúidas repetidas dentro de los 2grams, si es asi lo elimina\n",
    "                if((qs[i]+' '+qs[i+1]) in top_2_palabras_n[0][p1]):\n",
    "                    eliminar.append(top_2_palabras_n[0][p1])\n",
    "                    index_eliminar_2.append(p1)\n",
    "                    top_2_palabras_n[0][p1]='-4'\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    #Pensado para 20 palabras mas comunes de 3 palabras, compara contra las de 3 y las de 2\n",
    "    qs3=re.findall('[\\w]{1,15}',top_3_palabras_n[0][j])\n",
    "    # 3 palabras solo va a ir contra 2\n",
    "    for i in range(0,len(qs3)):\n",
    "        for p1 in range(0,qty_most_common):\n",
    "            try: #Mira si hay 3 palabras segúidas repetidas dentro de los fourgrams, si es asi lo elimina\n",
    "                if(((qs3[i]+' '+qs3[i+1]) in top_3_palabras_n[0][p1])&(p1!=j)):\n",
    "                    eliminar.append(top_3_palabras_n[0][p1])\n",
    "                    index_eliminar_3.append(p1)\n",
    "                    top_3_palabras_n[0][p1]='-3'\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try: #Mira si hay 2 palabras segúidas repetidas dentro de los fourgrams, si es asi lo elimina\n",
    "                if((qs3[i]+' '+qs3[i+1]) in top_2_palabras_n[0][p1]):\n",
    "                    eliminar.append(top_2_palabras_n[0][p1])\n",
    "                    index_eliminar_2.append(p1)\n",
    "                    top_2_palabras_n[0][p1]='-3'\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "#ELIMINA LAS FRASES QUE EL PROCESO ELIGIÓ LIMPIAR\n",
    "for b in range(0,len(eliminar)):\n",
    "    index_a_eliminar=Encuestas3[Encuestas3['frases']==eliminar[b]].index\n",
    "    Encuestas3.loc[index_a_eliminar,'frases']='' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193ccc08-4e4a-4f70-950c-f065c4574d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encuestas3.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a60ed7fc-c9fc-4a1c-be75-a8c8c8927a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'un buen servicio', 'mas informacion', 'mas proyectos',\n",
       "       'mas apoyo', 'nuevos proyectos', 'mas publicidad', 'poder tener',\n",
       "       'publicidad para los puntos', 'por parte de efecty', 'cada dia',\n",
       "       'servicios publicos', 'mas rapido', 'sieweb live',\n",
       "       'el tiempo de respuesta', 'cada punto', 'mas acompañamiento',\n",
       "       'la prestacion del servicio', 'puntos nuevos',\n",
       "       'servicio al cliente', 'parte de los logisticos', 'ser mas',\n",
       "       'ahorro a la mano', 'seria bueno', 'muchas veces',\n",
       "       'giros internacionales', 'seria muy bueno', 'el punto de servicio',\n",
       "       'la devolucion del dinero', 'mas convenios', 'excelente servicio',\n",
       "       'pendientes de los puntos', 'adulto mayor', 'del grupo aval',\n",
       "       'nequi y daviplata', 'nequi daviplata', 'tener mas',\n",
       "       'para mejorar el servicio', 'convenio con bancolombia',\n",
       "       'fondo nacional del ahorro', 'los tiempos de respuesta',\n",
       "       'los puntos de atencion', 'detalles para los clientes',\n",
       "       'el servicio de daviplata', 'los convenios del corresponsal',\n",
       "       'la plataforma de sieweb', 'fallas en el sistema',\n",
       "       'ninguna por el momento', 'la mesa de ayuda',\n",
       "       'prestar un mejor servicio', 'de agua y luz',\n",
       "       'todos los servicios pãºblicos', 'tener en cuenta',\n",
       "       'banco mundo mujer'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encuestas3['frases'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1225a8fb-4282-4d15-8ec8-719151b5b58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_inicial</th>\n",
       "      <th>Descripción</th>\n",
       "      <th>frases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0</td>\n",
       "      <td>no por el momento</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1</td>\n",
       "      <td>ninguno</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5578</th>\n",
       "      <td>2</td>\n",
       "      <td>en el tiempo de respuesta para prevalidar las consignaciones  un poco me gustaria que el proceso fuera mas agil</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2</td>\n",
       "      <td>en el tiempo de respuesta para prevalidar las consignaciones  un poco me gustaria que el proceso fuera mas agil</td>\n",
       "      <td>el tiempo de respuesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3</td>\n",
       "      <td>inestabilidad con algunos proyectos al hacer recaudos como por ejemplo claro y directv</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index_inicial  \\\n",
       "230   0               \n",
       "231   1               \n",
       "5578  2               \n",
       "232   2               \n",
       "233   3               \n",
       "\n",
       "                                                                                                          Descripción  \\\n",
       "230   no por el momento                                                                                                 \n",
       "231   ninguno                                                                                                           \n",
       "5578  en el tiempo de respuesta para prevalidar las consignaciones  un poco me gustaria que el proceso fuera mas agil   \n",
       "232   en el tiempo de respuesta para prevalidar las consignaciones  un poco me gustaria que el proceso fuera mas agil   \n",
       "233   inestabilidad con algunos proyectos al hacer recaudos como por ejemplo claro y directv                            \n",
       "\n",
       "                      frases  \n",
       "230                           \n",
       "231                           \n",
       "5578                          \n",
       "232   el tiempo de respuesta  \n",
       "233                           "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encuestas3['frases'].unique()\n",
    "Encuestas3[['index_inicial','Descripción','frases']].sort_values(by='index_inicial').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9bd10f1-5b27-4198-98af-8828822710d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta3= \"C:/Users/Usuario/Desktop/Respositorio archivos .py/borrador/Frases_encuestas.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094b4e2e-cf95-4bb3-8768-ffe0cede2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "#Ingreso las bases a hojas al archivo\n",
    "writer = pd.ExcelWriter(ruta3, engine='openpyxl')\n",
    "Encuestas3[['index_inicial','Descripción','frases']].to_excel(writer, index=True)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
